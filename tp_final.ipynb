{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo práctico final - NLP\n",
    "\n",
    "## Alumno: Garay Gorta, Isaías.\n",
    "\n",
    "El tema elegido es el lenguaje *Python*, para esto se utilizará la documentación oficial de *Python* y un dataset de *Kaggle* con los proyectos más populares para este lenguaje en el año 2023.\n",
    "\n",
    "- [Documentación Python](https://docs.python.org/es/3/download.html)\n",
    "- [Dataset Kaggle](https://www.kaggle.com/datasets/yeoyunsianggeremie/most-popular-python-projects-on-github-2018-2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1 - RAG\n",
    "\n",
    "Crear un chatbot experto en un tema a elección, usando la técnica RAG (Retrieval Augmented Generation).\n",
    "Como fuentes de conocimiento se utilizarán al menos las siguientes fuentes:\n",
    "- Documentos de texto\n",
    "- Datos numéricos en formato tabular (por ej., Dataframes, CSV, sqlite, etc.)\n",
    "- Base de datos de grafos (Online o local)\n",
    "\n",
    "El sistema debe poder llevar a cabo una conversación en lenguaje español. El usuario podrá hacer preguntas, que el chatbot intentará responder a partir de datos de algunas de sus fuentes. El asistente debe poder clasificar las preguntas, para saber qué fuentes de datos utilizar como contexto para generar una respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2024-02-13 21:29:39.897593: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-13 21:29:39.897647: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-13 21:29:40.042478: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-13 21:29:40.278775: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-13 21:29:41.566188: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[nltk_data] Downloading package stopwords to /home/isaias/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/isaias/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "import unicodedata\n",
    "import chromadb\n",
    "import gdown\n",
    "import fitz\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descargamos los archivos necesarios si no existe la carpeta `datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_DRIVE = 'https://drive.google.com/drive/folders/15cRVZcyHEJqSCgwMjdiFvFM9LFHTetbv?usp=drive_link'\n",
    "\n",
    "if not os.path.exists('datasets/'):\n",
    "    gdown.download_folder(URL_DRIVE, quiet=True, output='datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos tabulares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_proyectos_python = pd.read_csv('datasets/popular_python_projects_2023.csv')\n",
    "\n",
    "def buscar_proyecto(proyecto):\n",
    "    # Filtramos por nombre\n",
    "    bool_df = df_proyectos_python['repo_name'].str.contains(proyecto)\n",
    "\n",
    "    # Obtenemos la descripción del primer registro\n",
    "    # que cumple el criterio de busqueda.\n",
    "\n",
    "    desc = str()\n",
    "\n",
    "    if bool_df.any():\n",
    "        desc = df_proyectos_python[bool_df].iloc[0]['description']\n",
    "\n",
    "    return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Recommender system and evaluation framework for top-n recommendations tasks that respects polarity of feedbacks. Fast, flexible and easy to use. Written in python, boosted by scientific python stack.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buscar_proyecto('polar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base de datos vectorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('spanish'))\n",
    "\n",
    "def texto_de_pdf(pdf_path):\n",
    "  '''\n",
    "  Recibe el path a un archivo pdf y devuelve \n",
    "  su contenido en un string.\n",
    "  '''\n",
    "  texto = str()\n",
    "\n",
    "  doc = fitz.open(pdf_path)\n",
    "  for page in doc:\n",
    "    texto += page.get_text()\n",
    "\n",
    "  return texto\n",
    "\n",
    "def limpiar_texto(string):\n",
    "  '''\n",
    "  Recibe un string, lo pasa a minúscula\n",
    "  y elimina un formato que aparece en el índice\n",
    "  '''\n",
    "  return string.replace(' .', '').lower()\n",
    "\n",
    "def quitar_tildes(input_str):\n",
    "  '''\n",
    "  Recibe un string y elimina las tildes\n",
    "  '''\n",
    "  \n",
    "  nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "  return ''.join([c for c in nfkd_form if not unicodedata.combining(c)])\n",
    "\n",
    "def quitar_stopwords(text):\n",
    "  '''\n",
    "  Recibe un string y elimina las stopswords\n",
    "  '''\n",
    "\n",
    "  word_tokens = word_tokenize(text)\n",
    "  filtered_text = [word for word in word_tokens if word.casefold() not in stop_words]\n",
    "  return ' '.join(filtered_text)\n",
    "\n",
    "\n",
    "def procesar_string(string):\n",
    "  '''\n",
    "  Recibe un string y aplica la \n",
    "  normalización a su texto\n",
    "  '''\n",
    "\n",
    "  texto = limpiar_texto(string)\n",
    "  texto = quitar_tildes(texto)\n",
    "  texto = quitar_stopwords(texto)\n",
    "\n",
    "  return texto\n",
    "\n",
    "def procesar_texto(pdf_path):\n",
    "  '''\n",
    "  Recibe el path a un pdf y aplica la \n",
    "  normalización a su texto\n",
    "  '''\n",
    "\n",
    "  texto = texto_de_pdf(pdf_path)\n",
    "  texto = limpiar_texto(texto)\n",
    "  texto = quitar_tildes(texto)\n",
    "  texto = quitar_stopwords(texto)\n",
    "\n",
    "  return texto\n",
    "\n",
    "def dict_texto(directorio_pdf):\n",
    "    '''\n",
    "    Recibe el nombre de un directorio, devuelve un diccionario\n",
    "    donde la clave es el nombre del archivo pdf y su valor es\n",
    "    una lista con chunks del texto procesado del pdf.\n",
    "    '''\n",
    "\n",
    "    dict_pdf = dict()\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=1000,\n",
    "                chunk_overlap=150)\n",
    "\n",
    "    for file in os.listdir(directorio_pdf):\n",
    "        if not file.endswith('.pdf'):\n",
    "            continue\n",
    "        \n",
    "        path_pdf = f'{directorio_pdf}/{file}'\n",
    "\n",
    "        txt = splitter.split_text(procesar_texto(path_pdf))\n",
    "\n",
    "        dict_pdf[file] = txt\n",
    "\n",
    "    return dict_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos el texto de los archivos con las funciones definidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pdfs = dict_texto('datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a vectorizar el texto con un modelo de embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder-multilingual/3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además creamos la instancia de la base de datos `ChromaDB` donde vamos a almacenar los embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.Client()\n",
    "collection = client.get_or_create_collection('documentacion_python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 21:30:34.980688: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 314593280 exceeds 10% of free system memory.\n",
      "2024-02-13 21:30:35.037440: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 157296640 exceeds 10% of free system memory.\n",
      "2024-02-13 21:30:35.037500: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 157296640 exceeds 10% of free system memory.\n",
      "2024-02-13 21:30:35.037528: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 157296640 exceeds 10% of free system memory.\n",
      "2024-02-13 21:30:35.309445: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 157296640 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "def almacenar_texto(dicc, collection):\n",
    "    '''\n",
    "    Recibe un diccionario y una colección para almacenar\n",
    "    embeddings, itera sobre cada key del diccionario, vectoriza\n",
    "    los chunks de texto y los almacena en la colección.\n",
    "    '''\n",
    "    for key in dicc.keys():\n",
    "        embeddings = embed(dicc[key]).numpy().tolist()\n",
    "        chunks = dicc[key]\n",
    "        ids = [f'documento_{key}-parte{i}' \n",
    "               for i in range(1, len(chunks) + 1)]\n",
    "        \n",
    "        collection.add(\n",
    "                documents=chunks,\n",
    "                embeddings=embeddings,\n",
    "                ids=ids)\n",
    "        \n",
    "almacenar_texto(dict_pdfs, collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base de datos de grafos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fuente de estos datos será la base de datos online DBpedia. Se va a usar para conceptos general de programación que no se encuentren en los embeddings de los pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JavaScript (abreviado comúnmente JS) es un lenguaje de programación interpretado, dialecto del estándar ECMAScript. Se define como orientado a objetos,\\u200b basado en prototipos, , débilmente tipado y dinámico. Se utiliza principalmente del  lado del cliente, implementado como parte de un navegador web permitiendo mejoras en la interfaz de usuario y páginas web dinámicas\\u200b y JavaScript del lado del servidor (Server-side JavaScript o SSJS). Su uso en aplicaciones externas a la web, por ejemplo en documentos PDF, aplicaciones de escritorio (mayoritariamente widgets) es también significativo. Desde 2012, todos los navegadores modernos soportan completamente ECMAScript 5.1, una versión de JavaScript. Los navegadores más antiguos soportan por lo menos ECMAScript 3. La sexta edición se liberó en julio de 2015.\\u200b JavaScript se diseñó con una sintaxis similar a C [cita requerida], aunque adopta nombres y convenciones del lenguaje de programación Java. Sin embargo, Java y JavaScript tienen semánticas y propósitos diferentes. Todos los navegadores modernos interpretan el código JavaScript integrado en las páginas web. Para interactuar con una página web se provee al lenguaje JavaScript de una implementación del Document Object Model (DOM). Tradicionalmente se venía utilizando en páginas web HTML para realizar operaciones y únicamente en el marco de la aplicación cliente, sin acceso a funciones del servidor. Actualmente es ampliamente utilizado para enviar y recibir información del servidor junto con ayuda de otras tecnologías como AJAX. JavaScript se interpreta en el agente de usuario al mismo tiempo que las sentencias van descargándose junto con el código HTML. Desde el lanzamiento en junio de 1997 del estándar ECMAScript 1, han existido las versiones 2, 3 y 5, que es la más usada actualmente (la 4 se abandonó\\u200b). En junio de 2015 se cerró y publicó la versión ECMAScript 6.\\u200b'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "def ejecutar_consulta_sparql(consulta):\n",
    "    '''\n",
    "    Ejecuta una consulta SPARQL en la base de datos DBpedia en español.\n",
    "    '''\n",
    "    sparql = SPARQLWrapper(\"http://es.dbpedia.org/sparql\")\n",
    "    sparql.setQuery(consulta)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    resultados = sparql.query().convert()\n",
    "    return resultados\n",
    "\n",
    "def extraer_concepto_programacion(consulta):\n",
    "    '''\n",
    "    Función para extraer el concepto de programación de una consulta.\n",
    "    '''\n",
    "\n",
    "    nlp = spacy.load('es_core_news_lg')\n",
    "    texto = nlp(consulta)\n",
    "\n",
    "    resultado = str()\n",
    "\n",
    "    # Si se encuentre al menos una entidad\n",
    "    # en la consulta se devuelve la primera.\n",
    "    if texto.ents:\n",
    "        resultado = texto.ents[0]\n",
    "\n",
    "    return resultado\n",
    "\n",
    "def consultar_dbpedia(consulta):\n",
    "    '''\n",
    "    Consulta la base de datos DBpedia en español para obtener\n",
    "    información sobre un concepto de programación específico.\n",
    "    '''\n",
    "\n",
    "    concepto = extraer_concepto_programacion(consulta)\n",
    "\n",
    "    consulta_sparql = f'''\n",
    "    PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    \n",
    "    SELECT ?resource ?label ?abstract ?tipo\n",
    "    WHERE {{\n",
    "        ?resource a dbo:ProgrammingLanguage ;\n",
    "                  rdfs:label ?label ;\n",
    "                  dbo:abstract ?abstract .\n",
    "        FILTER(LANG(?label) = \"es\" && LANG(?abstract) = \"es\" && CONTAINS(?label, \"{concepto}\"))\n",
    "        OPTIONAL {{ ?resource rdf:type ?tipo }}\n",
    "    }}\n",
    "    LIMIT 1\n",
    "    '''\n",
    "\n",
    "    resultados = ejecutar_consulta_sparql(consulta_sparql)\n",
    "\n",
    "    if concepto and resultados['results']['bindings']:\n",
    "        concepto = resultados['results']['bindings'][0]['abstract']['value']\n",
    "    else:\n",
    "        concepto = f'No puede encontrar nada en DBpedia sobre: \\'{consulta}\\''\n",
    "\n",
    "    return concepto\n",
    "\n",
    "# Ejemplo de uso:\n",
    "ejemplo_consulta = 'Que es JavaScript?'\n",
    "consultar_dbpedia(ejemplo_consulta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elección de la fuente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se crea una función que recibirá una consulta del usuario y decidirá cuál de las fuentes es más probable que pueda llegar a responder la consulta. Para se utiliza un modelo pre-entrenado para la generación de embeddings de oraciones utilizando `SentenceTransformer` con el modelo `paraphrase-MiniLM-L6-v2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Cargamos el modelo\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "consultas_ejemplo = {\n",
    "    'grafo': ['Qué es Java?'],\n",
    "    'csv': ['Proyectos populares Python', 'Que es el proyecto pandas?'],\n",
    "    'vectores': ['Qué es Python?']\n",
    "}\n",
    "\n",
    "def determinar_fuente(consulta, consultas_ejemplo):\n",
    "    '''\n",
    "    Determina la fuente más probable para responder\n",
    "    a una consulta mediante búsqueda de pocos disparos.\n",
    "    '''\n",
    "\n",
    "    # Umbral de similitud\n",
    "    UMBRAL_SIMILITUD = 0.3\n",
    "\n",
    "    # Generamos la representación embebida de la consulta del usuario\n",
    "    embedding_consulta = model.encode(consulta, convert_to_tensor=True)\n",
    "\n",
    "    # Obtenemos representaciones embebidas de los ejemplos de pocos disparos\n",
    "    ejemplos_embeddings = dict()\n",
    "    for fuente, ejemplos in consultas_ejemplo.items():\n",
    "        ejemplos_embeddings[fuente] = model.encode(ejemplos,\n",
    "                                                   convert_to_tensor=True)\n",
    "\n",
    "    # Se calcula similitud coseno entre la consulta y cada conjunto de ejemplos\n",
    "    similitudes = dict()\n",
    "    for fuente, embeddings in ejemplos_embeddings.items():\n",
    "        similitudes[fuente] = util.pytorch_cos_sim(embedding_consulta,\n",
    "                                                   embeddings).mean().item()\n",
    "\n",
    "    # Finalmente se devuelve la fuente de datos con la similitud más alta\n",
    "    fuente_probable = max(similitudes, key=similitudes.get)\n",
    "    if similitudes[fuente_probable] < UMBRAL_SIMILITUD:\n",
    "      fuente_probable = str()\n",
    "    return fuente_probable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from jinja2 import Template\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_respuesta(prompt, max_new_tokens=768):\n",
    "  try:\n",
    "    api_key = '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'\n",
    "    api_url = 'https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-beta'\n",
    "\n",
    "    headers = None\n",
    "    if api_key:\n",
    "      headers = {'Authorization': f'Bearer {api_key}'}\n",
    "\n",
    "    data = {\n",
    "    'inputs': prompt,\n",
    "    'parameters': {\n",
    "    'max_new_tokens': max_new_tokens,\n",
    "    'temperature': 0.7,\n",
    "    'top_k': 50,\n",
    "    'top_p': 0.95}\n",
    "    }\n",
    "    \n",
    "    if headers:\n",
    "      # Realizamos la solicitud POST\n",
    "      response = requests.post(api_url, headers=headers, json=data)\n",
    "      # Se extrae la respuesta\n",
    "      respuesta = response.json()[0]['generated_text'][len(prompt):]\n",
    "      return respuesta\n",
    "  except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_jira(messages, add_generation_prompt=True):\n",
    "  \n",
    "  # Definimos la plantilla jinja\n",
    "  template_str = \"{% for message in messages %}\"\n",
    "  template_str += \"{% if message['role'] == 'user' %}\"\n",
    "  template_str += \"<|user|>{{ message['content'] }}</s>\\n\"\n",
    "  template_str += \"{% elif message['role'] == 'assistant' %}\"\n",
    "  template_str += \"<|assistant|>{{ message['content'] }}</s>\\n\"\n",
    "  template_str += \"{% elif message['role'] == 'system' %}\"\n",
    "  template_str += \"<|system|>{{ message['content'] }}</s>\\n\"\n",
    "  template_str += \"{% else %}\"\n",
    "  template_str += \"<|unknown|>{{ message['content'] }}</s>\\n\"\n",
    "  template_str += \"{% endif %}\"\n",
    "  template_str += \"{% endfor %}\"\n",
    "  template_str += \"{% if add_generation_prompt %}\"\n",
    "  template_str += \"<|assistant|>\\n\"\n",
    "  template_str += \"{% endif %}\"\n",
    "  \n",
    "  # Se crea una instancia de plantilla con el string\n",
    "  template = Template(template_str)\n",
    "\n",
    "  # Renderizar la plantilla con los mensajes proporcionados\n",
    "  return template.render(messages=messages,\n",
    "                         add_generation_prompt=add_generation_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_prompt(query_str, context_info):\n",
    "  '''\n",
    "  Función que recibe la pregunta del usuario y el contexto\n",
    "  que puede responder esa pregunta para armar el prompt \n",
    "  que usará el modelo.\n",
    "  '''\n",
    "\n",
    "  prompt = (\n",
    "  'La información de contexto es la siguiente:\\n'\n",
    "  '--------------------------\\n'\n",
    "  '{context_str}\\n'\n",
    "  '--------------------------\\n'\n",
    "  'Dada la información de contexto anterior, y sin utilizar conocimiento previo, responde en español la siguiente pregunta.\\n'\n",
    "  'Pregunta: {query_str}\\n'\n",
    "  'Respuesta: '\n",
    "  )\n",
    "\n",
    "  context_str = context_info\n",
    "  messages = [\n",
    "  {\n",
    "  'role': 'system',\n",
    "  'content': 'Eres un asistente útil que siempre responde con respuestas veraces, útiles y basadas en hechos.',\n",
    "  },\n",
    "  {'role': 'user', 'content': prompt.format(context_str=context_str, query_str=query_str)},\n",
    "  ]\n",
    "  final_prompt = template_jira(messages)\n",
    "  return final_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contexto_fuente_externa(fuente, consulta):\n",
    "  '''\n",
    "  Recibe la consulta del usuario y determine que \n",
    "  fuente de información es pertinente pare responerla.\n",
    "  '''\n",
    "  context_info = str()\n",
    "\n",
    "  if fuente == 'csv':\n",
    "    nombre_proyecto = str(extraer_concepto_programacion('que es el proyecto Pandas')).lower()\n",
    "    desc_proyecto   = buscar_proyecto(nombre_proyecto)\n",
    "    if desc_proyecto:\n",
    "      context_info = f'La descripción del proyecto es: {desc_proyecto}'\n",
    "    else:\n",
    "      context_info = f'Para responder la pregunta tienes que usar todo el csv:\\n{df_proyectos_python}'\n",
    "  elif fuente == 'grafo':\n",
    "    info_dbpedia = consultar_dbpedia(consulta)\n",
    "    context_info += f'{info_dbpedia}\\n'\n",
    "  elif fuente == 'vectores':\n",
    "    embedding_consulta = embed([consulta]).numpy().tolist()\n",
    "    results = collection.query(\n",
    "                query_embeddings=embedding_consulta,\n",
    "                n_results=3 )\n",
    "    \n",
    "    if results['documents']:\n",
    "      for result in results['documents']:\n",
    "        for text in result:\n",
    "          context_info += f'{text}\\n'\n",
    "  \n",
    "  return context_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo de uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuente de contexto seleccionada: vectores\n",
      "Pregunta: Qué es Python?\n",
      "Respuesta:\n",
      "Python es un lenguaje de programación que se utiliza en todo el mundo y se encuentra siendo publicado en mayor cantidad. Para obtener más información, puedes consultar la lista de libros de Python en wiki.python.org o buscar \"Python\" en las bibliotecas. Python también se refiere a una organización llamada Python Software Foundation, sin embargo, no hay restricciones de copyright en el uso de Python. Python fue llamado así por su creador, Guido van Rossum, quien pensó que necesitaba un nombre corto y ligeramente misterioso, luego decidió llamarlo Python. Se discuten nuevos desarrollos de Python en la lista de correo electrónico python-dev. Python es usado ampliamente en el mundo real, y hay millones de líneas de código de Python alrededor del mundo. Se puede obtener la documentación de Python y el código fuente en la página web de Python. Además, se puede encontrar artículos publicados sobre Python que pueden ser referidos.\n",
      "-------------------------------------------------------\n",
      "Fuente de contexto seleccionada: vectores\n",
      "Pregunta: Top 5 proyectos de Python en 2023\n",
      "Respuesta:\n",
      "1. Django: Django es un marco web de alto nivel escrito en Python que permite la creación de aplicaciones web robustas y seguras. Es utilizado por empresas y organizaciones importantes como The Washington Post, Mozilla, y Spotify. En 2023, se espera que Django siga siendo una de las principales opciones para el desarrollo web en Python debido a su amplia comunidad de desarrolladores y la disponibilidad de numerosos plug-ins y temas.\n",
      "\n",
      "2. Flask: Flask es un microframework web ligero y flexible escrito en Python. Es ideal para proyectos pequeños y medianos que requieren una mayor cantidad de control sobre el framework. Flask es utilizado por empresas como IBM, Google, y Pinterest. En 2023, se espera que Flask siga siendo una opción popular debido a su facilidad de uso y la disponibilidad de una amplia variedad de extensiones y plugins.\n",
      "\n",
      "3. PyTorch: PyTorch es un framework de aprendizaje automático (ML) y procesamiento neuronal (NLP) escrito en Python. Es utilizado por empresas y organizaciones como Facebook, Airbnb, y Uber. En 2023, se espera que PyTorch siga siendo una de las principales opciones para el desarrollo de ML y NLP debido a su amplia variedad de bibliotecas y herramientas disponibles.\n",
      "\n",
      "4. FastAPI: FastAPI es un marco web moderno y rápido escrito en Python que permite la creación de APIs web con un enfoque en la velocidad y la simplicidad. Es utilizado por empresas como Red Hat y DigitalOcean. En 2023, se espera que FastAPI siga siendo una opción popular debido a su velocidad y la disponibilidad de una amplia variedad de recursos y plugins.\n",
      "\n",
      "5. Rasa: Rasa es un framework de diálogo y asistencia virtual escrito en Python. Es utilizado por empresas como Deutsche Bank, Audi, y Vodafone. En 2023, se espera que Rasa siga siendo una opción popular debido a su amplia variedad de recursos y plugins para el desarrollo de diálogos y asistencia virtual.\n",
      "\n",
      "Es importante mencionar que estas opciones son solo una perspectiva y se pueden agregar otras proyectos importantes de Python en el futuro. Sin embargo, estos proyectos se espera que sigan siendo populares debido a su utilidad y la disponibilidad de una amplia comunidad de desarrolladores.\n",
      "-------------------------------------------------------\n",
      "Fuente de contexto seleccionada: grafo\n",
      "Pregunta: Qué es Java?\n",
      "Respuesta:\n",
      "Java es un lenguaje de programación orientado a objetos, diseñado con una sintaxis similar a C, utilizado principalmente para desarrollar aplicaciones de escritorio y servidores. Sin embargo, JavaScript y Java tienen semánticas y propósitos diferentes. Mientras JavaScript se utiliza principalmente para mejorar la interfaz de usuario y las páginas web dinámicas desde el lado del cliente, Java se utiliza para desarrollar aplicaciones de escritorio y servidores en diferentes plataformas, incluyendo dispositivos móviles y servidores web.\n",
      "-------------------------------------------------------\n",
      "Fuente de contexto seleccionada: vectores\n",
      "Pregunta: Cómo estás?\n",
      "Respuesta:\n",
      "Respuesta: Estoy bien, gracias por preguntar. Como usted puede ver, estoy aquí para ayudarle con cualquier consulta relacionada con el lenguaje de programación Python. Estoy programado para proporcionar respuestas verdaderas, útiles y basadas en hechos. Estoy en disposición de ayudarlo en cualquier momento. ¡Gracias por elegir a Python como su lenguaje de programación preferido! \n",
      "\n",
      "En términos del contexto proporcionado, esta conversación se encuentra dentro de un documento de referencia para el lenguaje de programación Python. El texto muestra una lista de preguntas y respuestas relacionadas con Python, y la pregunta actual se refiere a la forma en que estoy. La respuesta refleja la función de un asistente, que está listo para ayudar con cualquier consulta sobre Python, sin la necesidad de un conocimiento previo.\n",
      "-------------------------------------------------------\n",
      "Fuente de contexto seleccionada: csv\n",
      "Pregunta: Qué es el proyecto Pandas\n",
      "Respuesta:\n",
      "El proyecto Pandas, según su descripción, es una biblioteca potente y flexible para análisis y manipulación de datos en Python, que proporciona estructuras etiquetadas de datos similares a los objetos data.frame de R, funciones estadísticas y muchas otras características.\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "consultas = ['Qué es Python?', 'Top 5 proyectos de Python en 2023',\n",
    "             'Qué es Java?', 'Cómo estás?', 'Qué es el proyecto Pandas']\n",
    "\n",
    "def procesar_pregunta(consultas):\n",
    "    for consulta in consultas:\n",
    "        # Traemos los documentos más relevantes para la consulta\n",
    "        fuente_contexto = determinar_fuente(consulta, consultas_ejemplo)\n",
    "        print(f'Fuente de contexto seleccionada: {fuente_contexto}')\n",
    "        context_text = contexto_fuente_externa(fuente_contexto, consulta)\n",
    "        final_prompt = None\n",
    "        if not fuente_contexto:\n",
    "            final_prompt = preparar_prompt(\n",
    "                f'Dar la respuesta en el idioma en que fue realizada la pregunta. Responder: {consulta}',\n",
    "                'No hay contexto adicional para esta consulta'\n",
    "            )\n",
    "        elif fuente_contexto == 'csv':\n",
    "            query_str_csv = f'Utiliza la descripción del proyecto o el archivo csv para responder esto: \\n {consulta}'\n",
    "            final_prompt = preparar_prompt(query_str_csv, str(context_text))\n",
    "        else:\n",
    "            final_prompt = preparar_prompt(consulta, context_text)\n",
    "        print('Pregunta:', consulta)\n",
    "        print('Respuesta:')\n",
    "        answer = generar_respuesta(final_prompt)\n",
    "        if answer:\n",
    "            print(answer)\n",
    "        else:\n",
    "            print('Error al generar la respuesta.')\n",
    "        print('-------------------------------------------------------')\n",
    "\n",
    "# Ejecutamos la función\n",
    "procesar_pregunta(consultas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola! Puedo responder tus preguntas sobre Python (para salir escriba 'q')\n",
      "Chau!\n"
     ]
    }
   ],
   "source": [
    "def chatbot():\n",
    "    '''\n",
    "    Función para interactuar con el bot.\n",
    "    '''\n",
    "\n",
    "    print('Hola! Puedo responder tus preguntas sobre Python (para salir escriba \\'q\\')')\n",
    "\n",
    "    while True:\n",
    "        # Obtener la pregunta del usuario\n",
    "        user_input = input('Usuario: ')\n",
    "\n",
    "        if user_input.lower() == 'q':\n",
    "            print('Chau!')\n",
    "            break\n",
    "\n",
    "        # user_input = procesar_string(user_input)\n",
    "\n",
    "        # Responder la pregunta\n",
    "        procesar_pregunta([user_input])\n",
    "\n",
    "chatbot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
